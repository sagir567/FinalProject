{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9206f3c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets==1.18.3 in /Users/mac/anaconda3/envs/wav2vec2Transforrmers/lib/python3.10/site-packages (1.18.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/mac/anaconda3/envs/wav2vec2Transforrmers/lib/python3.10/site-packages (from datasets==1.18.3) (1.26.4)\n",
      "Requirement already satisfied: pyarrow!=4.0.0,>=3.0.0 in /Users/mac/anaconda3/envs/wav2vec2Transforrmers/lib/python3.10/site-packages (from datasets==1.18.3) (14.0.2)\n",
      "Requirement already satisfied: dill in /Users/mac/anaconda3/envs/wav2vec2Transforrmers/lib/python3.10/site-packages (from datasets==1.18.3) (0.3.6)\n",
      "Requirement already satisfied: pandas in /Users/mac/anaconda3/envs/wav2vec2Transforrmers/lib/python3.10/site-packages (from datasets==1.18.3) (2.2.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/mac/anaconda3/envs/wav2vec2Transforrmers/lib/python3.10/site-packages (from datasets==1.18.3) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /Users/mac/anaconda3/envs/wav2vec2Transforrmers/lib/python3.10/site-packages (from datasets==1.18.3) (4.66.2)\n",
      "Requirement already satisfied: xxhash in /Users/mac/anaconda3/envs/wav2vec2Transforrmers/lib/python3.10/site-packages (from datasets==1.18.3) (2.0.2)\n",
      "Requirement already satisfied: multiprocess in /Users/mac/anaconda3/envs/wav2vec2Transforrmers/lib/python3.10/site-packages (from datasets==1.18.3) (0.70.14)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /Users/mac/anaconda3/envs/wav2vec2Transforrmers/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->datasets==1.18.3) (2024.3.1)\n",
      "Requirement already satisfied: aiohttp in /Users/mac/anaconda3/envs/wav2vec2Transforrmers/lib/python3.10/site-packages (from datasets==1.18.3) (3.9.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /Users/mac/anaconda3/envs/wav2vec2Transforrmers/lib/python3.10/site-packages (from datasets==1.18.3) (0.11.0)\n",
      "Requirement already satisfied: packaging in /Users/mac/anaconda3/envs/wav2vec2Transforrmers/lib/python3.10/site-packages (from datasets==1.18.3) (23.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/mac/anaconda3/envs/wav2vec2Transforrmers/lib/python3.10/site-packages (from aiohttp->datasets==1.18.3) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/mac/anaconda3/envs/wav2vec2Transforrmers/lib/python3.10/site-packages (from aiohttp->datasets==1.18.3) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/mac/anaconda3/envs/wav2vec2Transforrmers/lib/python3.10/site-packages (from aiohttp->datasets==1.18.3) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/mac/anaconda3/envs/wav2vec2Transforrmers/lib/python3.10/site-packages (from aiohttp->datasets==1.18.3) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/mac/anaconda3/envs/wav2vec2Transforrmers/lib/python3.10/site-packages (from aiohttp->datasets==1.18.3) (1.9.3)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /Users/mac/anaconda3/envs/wav2vec2Transforrmers/lib/python3.10/site-packages (from aiohttp->datasets==1.18.3) (4.0.3)\n",
      "Requirement already satisfied: filelock in /Users/mac/anaconda3/envs/wav2vec2Transforrmers/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets==1.18.3) (3.13.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/mac/anaconda3/envs/wav2vec2Transforrmers/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets==1.18.3) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/mac/anaconda3/envs/wav2vec2Transforrmers/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets==1.18.3) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/mac/anaconda3/envs/wav2vec2Transforrmers/lib/python3.10/site-packages (from requests>=2.19.0->datasets==1.18.3) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/mac/anaconda3/envs/wav2vec2Transforrmers/lib/python3.10/site-packages (from requests>=2.19.0->datasets==1.18.3) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/mac/anaconda3/envs/wav2vec2Transforrmers/lib/python3.10/site-packages (from requests>=2.19.0->datasets==1.18.3) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/mac/anaconda3/envs/wav2vec2Transforrmers/lib/python3.10/site-packages (from requests>=2.19.0->datasets==1.18.3) (2024.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/mac/anaconda3/envs/wav2vec2Transforrmers/lib/python3.10/site-packages (from pandas->datasets==1.18.3) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/mac/anaconda3/envs/wav2vec2Transforrmers/lib/python3.10/site-packages (from pandas->datasets==1.18.3) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/mac/anaconda3/envs/wav2vec2Transforrmers/lib/python3.10/site-packages (from pandas->datasets==1.18.3) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/mac/anaconda3/envs/wav2vec2Transforrmers/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets==1.18.3) (1.16.0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6eea5f668b374533b58dc98956834905",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import tokenizer\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import jiwer\n",
    "from huggingface_hub import notebook_login\n",
    "!pip install datasets==1.18.3\n",
    "import transformers \n",
    "notebook_login()\n",
    "import sys\n",
    "List = sys.path\n",
    "print(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "845974d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>test_or_train</th>\n",
       "      <th>dialect_region</th>\n",
       "      <th>speaker_id</th>\n",
       "      <th>filename</th>\n",
       "      <th>path_from_data_dir</th>\n",
       "      <th>path_from_data_dir_windows</th>\n",
       "      <th>is_converted_audio</th>\n",
       "      <th>is_audio</th>\n",
       "      <th>is_word_file</th>\n",
       "      <th>is_phonetic_file</th>\n",
       "      <th>is_sentence_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>DR4</td>\n",
       "      <td>MMDM0</td>\n",
       "      <td>SI681.WAV.wav</td>\n",
       "      <td>TRAIN/DR4/MMDM0/SI681.WAV.wav</td>\n",
       "      <td>TRAIN\\\\DR4\\\\MMDM0\\\\SI681.WAV.wav</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>DR4</td>\n",
       "      <td>MMDM0</td>\n",
       "      <td>SI1311.PHN</td>\n",
       "      <td>TRAIN/DR4/MMDM0/SI1311.PHN</td>\n",
       "      <td>TRAIN\\\\DR4\\\\MMDM0\\\\SI1311.PHN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>DR4</td>\n",
       "      <td>MMDM0</td>\n",
       "      <td>SI1311.WRD</td>\n",
       "      <td>TRAIN/DR4/MMDM0/SI1311.WRD</td>\n",
       "      <td>TRAIN\\\\DR4\\\\MMDM0\\\\SI1311.WRD</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>DR4</td>\n",
       "      <td>MMDM0</td>\n",
       "      <td>SX321.PHN</td>\n",
       "      <td>TRAIN/DR4/MMDM0/SX321.PHN</td>\n",
       "      <td>TRAIN\\\\DR4\\\\MMDM0\\\\SX321.PHN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>DR4</td>\n",
       "      <td>MMDM0</td>\n",
       "      <td>SX321.WRD</td>\n",
       "      <td>TRAIN/DR4/MMDM0/SX321.WRD</td>\n",
       "      <td>TRAIN\\\\DR4\\\\MMDM0\\\\SX321.WRD</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8395</th>\n",
       "      <td>8396.0</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>DR2</td>\n",
       "      <td>MMAA0</td>\n",
       "      <td>SA2.WAV.wav</td>\n",
       "      <td>TRAIN/DR2/MMAA0/SA2.WAV.wav</td>\n",
       "      <td>TRAIN\\\\DR2\\\\MMAA0\\\\SA2.WAV.wav</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8396</th>\n",
       "      <td>8397.0</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>DR2</td>\n",
       "      <td>MMAA0</td>\n",
       "      <td>SX125.WAV.wav</td>\n",
       "      <td>TRAIN/DR2/MMAA0/SX125.WAV.wav</td>\n",
       "      <td>TRAIN\\\\DR2\\\\MMAA0\\\\SX125.WAV.wav</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8397</th>\n",
       "      <td>8398.0</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>DR2</td>\n",
       "      <td>MMAA0</td>\n",
       "      <td>SI845.WAV</td>\n",
       "      <td>TRAIN/DR2/MMAA0/SI845.WAV</td>\n",
       "      <td>TRAIN\\\\DR2\\\\MMAA0\\\\SI845.WAV</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8398</th>\n",
       "      <td>8399.0</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>DR2</td>\n",
       "      <td>MMAA0</td>\n",
       "      <td>SX35.TXT</td>\n",
       "      <td>TRAIN/DR2/MMAA0/SX35.TXT</td>\n",
       "      <td>TRAIN\\\\DR2\\\\MMAA0\\\\SX35.TXT</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8399</th>\n",
       "      <td>8400.0</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>DR2</td>\n",
       "      <td>MMAA0</td>\n",
       "      <td>SX35.WAV.wav</td>\n",
       "      <td>TRAIN/DR2/MMAA0/SX35.WAV.wav</td>\n",
       "      <td>TRAIN\\\\DR2\\\\MMAA0\\\\SX35.WAV.wav</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8400 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index test_or_train dialect_region speaker_id       filename  \\\n",
       "0        1.0         TRAIN            DR4      MMDM0  SI681.WAV.wav   \n",
       "1        2.0         TRAIN            DR4      MMDM0     SI1311.PHN   \n",
       "2        3.0         TRAIN            DR4      MMDM0     SI1311.WRD   \n",
       "3        4.0         TRAIN            DR4      MMDM0      SX321.PHN   \n",
       "4        5.0         TRAIN            DR4      MMDM0      SX321.WRD   \n",
       "...      ...           ...            ...        ...            ...   \n",
       "8395  8396.0         TRAIN            DR2      MMAA0    SA2.WAV.wav   \n",
       "8396  8397.0         TRAIN            DR2      MMAA0  SX125.WAV.wav   \n",
       "8397  8398.0         TRAIN            DR2      MMAA0      SI845.WAV   \n",
       "8398  8399.0         TRAIN            DR2      MMAA0       SX35.TXT   \n",
       "8399  8400.0         TRAIN            DR2      MMAA0   SX35.WAV.wav   \n",
       "\n",
       "                 path_from_data_dir        path_from_data_dir_windows  \\\n",
       "0     TRAIN/DR4/MMDM0/SI681.WAV.wav  TRAIN\\\\DR4\\\\MMDM0\\\\SI681.WAV.wav   \n",
       "1        TRAIN/DR4/MMDM0/SI1311.PHN     TRAIN\\\\DR4\\\\MMDM0\\\\SI1311.PHN   \n",
       "2        TRAIN/DR4/MMDM0/SI1311.WRD     TRAIN\\\\DR4\\\\MMDM0\\\\SI1311.WRD   \n",
       "3         TRAIN/DR4/MMDM0/SX321.PHN      TRAIN\\\\DR4\\\\MMDM0\\\\SX321.PHN   \n",
       "4         TRAIN/DR4/MMDM0/SX321.WRD      TRAIN\\\\DR4\\\\MMDM0\\\\SX321.WRD   \n",
       "...                             ...                               ...   \n",
       "8395    TRAIN/DR2/MMAA0/SA2.WAV.wav    TRAIN\\\\DR2\\\\MMAA0\\\\SA2.WAV.wav   \n",
       "8396  TRAIN/DR2/MMAA0/SX125.WAV.wav  TRAIN\\\\DR2\\\\MMAA0\\\\SX125.WAV.wav   \n",
       "8397      TRAIN/DR2/MMAA0/SI845.WAV      TRAIN\\\\DR2\\\\MMAA0\\\\SI845.WAV   \n",
       "8398       TRAIN/DR2/MMAA0/SX35.TXT       TRAIN\\\\DR2\\\\MMAA0\\\\SX35.TXT   \n",
       "8399   TRAIN/DR2/MMAA0/SX35.WAV.wav   TRAIN\\\\DR2\\\\MMAA0\\\\SX35.WAV.wav   \n",
       "\n",
       "     is_converted_audio is_audio is_word_file is_phonetic_file  \\\n",
       "0                  True     True        False            False   \n",
       "1                 False    False        False             True   \n",
       "2                 False    False         True            False   \n",
       "3                 False    False        False             True   \n",
       "4                 False    False         True            False   \n",
       "...                 ...      ...          ...              ...   \n",
       "8395               True     True        False            False   \n",
       "8396               True     True        False            False   \n",
       "8397              False     True        False            False   \n",
       "8398              False    False        False            False   \n",
       "8399               True     True        False            False   \n",
       "\n",
       "     is_sentence_file  \n",
       "0               False  \n",
       "1               False  \n",
       "2               False  \n",
       "3               False  \n",
       "4               False  \n",
       "...               ...  \n",
       "8395            False  \n",
       "8396            False  \n",
       "8397            False  \n",
       "8398             True  \n",
       "8399            False  \n",
       "\n",
       "[8400 rows x 12 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_train = pd.read_csv('DataSets/TIMIT/train_data.csv')\n",
    "df_train = df_train[:8400]\n",
    "df_train\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1abb6750",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset timit_asr (/Users/mac/.cache/huggingface/datasets/timit_asr/clean/2.0.1/b11b576ddcccbcefa7c9f0c4e6c2a43756f3033adffe0fb686aa61043d0450ad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8538433a5adb4f278338b93ad4fc7f20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset, load_metric\n",
    "\n",
    "timit = load_dataset(\"timit_asr\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "19c727e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['file', 'audio', 'text'],\n",
       "        num_rows: 4620\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['file', 'audio', 'text'],\n",
       "        num_rows: 1680\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timit = timit.remove_columns([\"phonetic_detail\", \"word_detail\", \"dialect_region\", \"id\", \"sentence_type\", \"speaker_id\"])\n",
    "timit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "847b74f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>She had your dark suit in greasy wash water all year.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Can the agency overthrow alien forces?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How safe is too safe?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Scholastic aptitude is judged by standardized tests.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We could barely see the fjords through the snow flurries.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>He blew his nose expertly between his fingers.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>We must be ready for any needed sacrifice.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Don't ask me to carry an oily rag like that.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Herb's birthday occurs frequently on Thanksgiving.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Don't plan meals that are too complicated.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import ClassLabel\n",
    "import random\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def show_random_elements(dataset, num_examples=10):\n",
    "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
    "    picks = []\n",
    "    for _ in range(num_examples):\n",
    "        pick = random.randint(0, len(dataset)-1)\n",
    "        while pick in picks:\n",
    "            pick = random.randint(0, len(dataset)-1)\n",
    "        picks.append(pick)\n",
    "    \n",
    "    df = pd.DataFrame(dataset[picks])\n",
    "    display(HTML(df.to_html()))\n",
    "\n",
    "show_random_elements(timit[\"train\"].remove_columns([\"file\", \"audio\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f0e1e6b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f9afa3f62484cfdae8180a487e6bae9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0ex [00:00, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c90267a1d7644bdbb0c93a9b8923da7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0ex [00:00, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import re\n",
    "chars_to_ignore_regex = '[\\,\\?\\.\\!\\-\\;\\:\\\"]'\n",
    "\n",
    "def remove_special_characters(batch):\n",
    "    batch[\"text\"] = re.sub(chars_to_ignore_regex, '', batch[\"text\"]).lower()\n",
    "    return batch\n",
    "\n",
    "timit = timit.map(remove_special_characters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3205204f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>she had your dark suit in greasy wash water all year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the saw is broken so chop the wood instead</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i know i didn't meet her early enough</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>this is a significant advance but its import should not be exaggerated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>women may never become completely equal to men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gently place jim's foam sculpture in the box</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>but they would reconsider it they assured him if he would rewrite it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>now don't tell me what a good ball player you are</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bruises and black eyes were relieved by application of raw beefsteak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>he smashed it in and tumbled into darkness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_random_elements(timit[\"train\"].remove_columns([\"file\", \"audio\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1cb5d044",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ed1de6f80ae42a68258d80c68e287a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58218977d9b046419df7b127bce24713",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def extract_all_chars(batch):\n",
    "    \n",
    "  all_text = \" \".join(batch[\"text\"])\n",
    "  b = set(all_text)\n",
    "    \n",
    "  vocab = list(b)\n",
    "  return {\"vocab\": [vocab], \"all_text\": [all_text]}\n",
    "\n",
    "vocabs = timit.map(extract_all_chars, batched=True, batch_size=-1, keep_in_memory=True, remove_columns=timit.column_names[\"train\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fed1c60f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'b': 0,\n",
       " 'h': 1,\n",
       " ' ': 2,\n",
       " 'a': 3,\n",
       " 'l': 4,\n",
       " 'w': 5,\n",
       " 'x': 6,\n",
       " 'f': 7,\n",
       " 'p': 8,\n",
       " 'r': 9,\n",
       " 'v': 10,\n",
       " 'u': 11,\n",
       " 'j': 12,\n",
       " 'z': 13,\n",
       " 'k': 14,\n",
       " 'd': 15,\n",
       " 's': 16,\n",
       " 'm': 17,\n",
       " 'o': 18,\n",
       " 'g': 19,\n",
       " 't': 20,\n",
       " \"'\": 21,\n",
       " 'i': 22,\n",
       " 'q': 23,\n",
       " 'e': 24,\n",
       " 'n': 25,\n",
       " 'y': 26,\n",
       " 'c': 27}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_list = list(set(vocabs[\"train\"][\"vocab\"][0]) | set(vocabs[\"test\"][\"vocab\"][0]))\n",
    "\n",
    "vocab_dict = {v: k for k, v in enumerate(vocab_list)}\n",
    "vocab_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5af3c345",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_dict[\"|\"] = vocab_dict[\" \"]\n",
    "del vocab_dict[\" \"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2eec96c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "vocab_dict[\"[UNK]\"] = len(vocab_dict)\n",
    "vocab_dict[\"[PAD]\"] = len(vocab_dict)\n",
    "print(len(vocab_dict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ce10c459",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('vocab.json', 'w') as vocab_file:\n",
    "    json.dump(vocab_dict, vocab_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5cf680c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_name = \"wav2vec2-base-timit-demo-colab\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aba8e55e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tokenizer' has no attribute 'push_to_hub'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtokenizer\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpush_to_hub\u001b[49m(repo_name)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tokenizer' has no attribute 'push_to_hub'"
     ]
    }
   ],
   "source": [
    "import tokenizer\n",
    "tokenizer.push_to_hub(repo_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83e33d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2CTCTokenizer\n",
    "\n",
    "tokenizer = Wav2Vec2CTCTokenizer(\"./vocab.json\", unk_token=\"[UNK]\", pad_token=\"[PAD]\", word_delimiter_token=\"|\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9389f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2FeatureExtractor\n",
    "\n",
    "feature_extractor = Wav2Vec2FeatureExtractor(feature_size=1, sampling_rate=16000, padding_value=0.0, do_normalize=True, return_attention_mask=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2c5fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2Processor\n",
    "\n",
    "processor = Wav2Vec2Processor(feature_extractor=feature_extractor, tokenizer=tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05f0dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "timit['train']['audio']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ee9fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as ipd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "rand_int = random.randint(0, len(timit[\"train\"]))\n",
    "\n",
    "print(timit[\"train\"][rand_int][\"text\"])\n",
    "ipd.Audio(data=np.asarray(timit[\"train\"][rand_int][\"audio\"][\"array\"]), autoplay=True, rate=16000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ed26c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_int = random.randint(0, len(timit[\"train\"]))\n",
    "\n",
    "print(\"Target text:\", timit[\"train\"][rand_int][\"text\"])\n",
    "print(\"Input array shape:\", np.asarray(timit[\"train\"][rand_int][\"audio\"][\"array\"]).shape)\n",
    "print(\"Sampling rate:\", timit[\"train\"][rand_int][\"audio\"][\"sampling_rate\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa0f3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(batch):\n",
    "    audio = batch[\"audio\"]\n",
    "\n",
    "    # batched output is \"un-batched\" to ensure mapping is correct\n",
    "    batch[\"input_values\"] = processor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_values[0]\n",
    "    \n",
    "    with processor.as_target_processor():\n",
    "        batch[\"labels\"] = processor(batch[\"text\"]).input_ids\n",
    "    return batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace9e161",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.object = object \n",
    "timit = timit.map(prepare_dataset, remove_columns=timit.column_names[\"train\"], num_proc=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3f4e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Any, Dict, List, Optional, Union\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorCTCWithPadding:\n",
    "    \"\"\"\n",
    "    Data collator that will dynamically pad the inputs received.\n",
    "    Args:\n",
    "        processor (:class:`~transformers.Wav2Vec2Processor`)\n",
    "            The processor used for proccessing the data.\n",
    "        padding (:obj:`bool`, :obj:`str` or :class:`~transformers.tokenization_utils_base.PaddingStrategy`, `optional`, defaults to :obj:`True`):\n",
    "            Select a strategy to pad the returned sequences (according to the model's padding side and padding index)\n",
    "            among:\n",
    "            * :obj:`True` or :obj:`'longest'`: Pad to the longest sequence in the batch (or no padding if only a single\n",
    "              sequence if provided).\n",
    "            * :obj:`'max_length'`: Pad to a maximum length specified with the argument :obj:`max_length` or to the\n",
    "              maximum acceptable input length for the model if that argument is not provided.\n",
    "            * :obj:`False` or :obj:`'do_not_pad'` (default): No padding (i.e., can output a batch with sequences of\n",
    "              different lengths).\n",
    "        max_length (:obj:`int`, `optional`):\n",
    "            Maximum length of the ``input_values`` of the returned list and optionally padding length (see above).\n",
    "        max_length_labels (:obj:`int`, `optional`):\n",
    "            Maximum length of the ``labels`` returned list and optionally padding length (see above).\n",
    "        pad_to_multiple_of (:obj:`int`, `optional`):\n",
    "            If set will pad the sequence to a multiple of the provided value.\n",
    "            This is especially useful to enable the use of Tensor Cores on NVIDIA hardware with compute capability >=\n",
    "            7.5 (Volta).\n",
    "    \"\"\"\n",
    "\n",
    "    processor: Wav2Vec2Processor\n",
    "    padding: Union[bool, str] = True\n",
    "    max_length: Optional[int] = None\n",
    "    max_length_labels: Optional[int] = None\n",
    "    pad_to_multiple_of: Optional[int] = None\n",
    "    pad_to_multiple_of_labels: Optional[int] = None\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        # split inputs and labels since they have to be of different lengths and need\n",
    "        # different padding methods\n",
    "        input_features = [{\"input_values\": feature[\"input_values\"]} for feature in features]\n",
    "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
    "\n",
    "        batch = self.processor.pad(\n",
    "            input_features,\n",
    "            padding=self.padding,\n",
    "            max_length=self.max_length,\n",
    "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        with self.processor.as_target_processor():\n",
    "            labels_batch = self.processor.pad(\n",
    "                label_features,\n",
    "                padding=self.padding,\n",
    "                max_length=self.max_length_labels,\n",
    "                pad_to_multiple_of=self.pad_to_multiple_of_labels,\n",
    "                return_tensors=\"pt\",\n",
    "            )\n",
    "\n",
    "        # replace padding with -100 to ignore loss correctly\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
    "\n",
    "        batch[\"labels\"] = labels\n",
    "\n",
    "        return batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0aa4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorCTCWithPadding(processor=processor, padding=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2954da",
   "metadata": {},
   "outputs": [],
   "source": [
    "wer_metric = load_metric(\"wer\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51508bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    pred_logits = pred.predictions\n",
    "    pred_ids = np.argmax(pred_logits, axis=-1)\n",
    "\n",
    "    pred.label_ids[pred.label_ids == -100] = processor.tokenizer.pad_token_id\n",
    "\n",
    "    pred_str = processor.batch_decode(pred_ids)\n",
    "    # we do not want to group tokens when computing the metrics\n",
    "    label_str = processor.batch_decode(pred.label_ids, group_tokens=False)\n",
    "\n",
    "    wer = wer_metric.compute(predictions=pred_str, references=label_str)\n",
    "\n",
    "    return {\"wer\": wer}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9686a1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2ForCTC\n",
    "\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\n",
    "    \"facebook/wav2vec2-base\", \n",
    "    ctc_loss_reduction=\"mean\", \n",
    "    pad_token_id=processor.tokenizer.pad_token_id,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362b0504",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.freeze_feature_extractor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa5faa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "  output_dir=repo_name,\n",
    "  group_by_length=True,\n",
    "  per_device_train_batch_size=32,\n",
    "  evaluation_strategy=\"steps\",\n",
    "  num_train_epochs=30,\n",
    "  \n",
    "  gradient_checkpointing=True, \n",
    "  save_steps=500,\n",
    "  eval_steps=500,\n",
    "  logging_steps=500,\n",
    "  learning_rate=1e-4,\n",
    "  weight_decay=0.005,\n",
    "  warmup_steps=1000,\n",
    "  save_total_limit=2,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692addaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    data_collator=data_collator,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=timit_prepared[\"train\"],\n",
    "    eval_dataset=timit_prepared[\"test\"],\n",
    "    tokenizer=processor.feature_extractor,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278b1ec2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
